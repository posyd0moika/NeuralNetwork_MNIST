{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist         # библиотека базы выборок Mnist\n",
    "from tensorflow import keras\n",
    "from extensionbase import gen_extension_base\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers.legacy import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 14, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               401536    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 421,642\n",
      "Trainable params: 421,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2), strides=2),\n",
    "    Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2), strides=2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10,  activation='softmax')\n",
    "])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 10s 16ms/step - loss: 0.2965 - accuracy: 0.9057\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.0624 - accuracy: 0.9822\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.0375 - accuracy: 0.9888\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.0191 - accuracy: 0.9947\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.0292 - accuracy: 0.9917\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.0146 - accuracy: 0.9956\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0198 - accuracy: 0.9944\n",
      "600/600 [==============================] - 12s 20ms/step - loss: 0.0216 - accuracy: 0.9939\n",
      "600/600 [==============================] - 13s 22ms/step - loss: 0.0137 - accuracy: 0.9961\n",
      "600/600 [==============================] - 12s 19ms/step - loss: 0.0192 - accuracy: 0.9943\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.0132 - accuracy: 0.9964\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0161 - accuracy: 0.9954\n",
      "600/600 [==============================] - 12s 19ms/step - loss: 0.0123 - accuracy: 0.9963\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0107 - accuracy: 0.9967\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0156 - accuracy: 0.9957\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0112 - accuracy: 0.9968\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0063 - accuracy: 0.9980\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0075 - accuracy: 0.9978\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0107 - accuracy: 0.9972\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0069 - accuracy: 0.9978\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0067 - accuracy: 0.9980\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0097 - accuracy: 0.9971\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0059 - accuracy: 0.9979\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0083 - accuracy: 0.9978\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0141 - accuracy: 0.9967\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0069 - accuracy: 0.9980\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0091 - accuracy: 0.9976\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0068 - accuracy: 0.9982\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0059 - accuracy: 0.9984\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0087 - accuracy: 0.9975\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0067 - accuracy: 0.9981\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0045 - accuracy: 0.9986\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0055 - accuracy: 0.9985\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0072 - accuracy: 0.9978\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0073 - accuracy: 0.9981\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0031 - accuracy: 0.9992\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0044 - accuracy: 0.9986\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0078 - accuracy: 0.9980\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0037 - accuracy: 0.9988\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0076 - accuracy: 0.9980\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0047 - accuracy: 0.9987\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0076 - accuracy: 0.9980\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0103 - accuracy: 0.9977\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0114 - accuracy: 0.9970\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0033 - accuracy: 0.9990\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0064 - accuracy: 0.9983\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0065 - accuracy: 0.9982\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0064 - accuracy: 0.9982\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0041 - accuracy: 0.9989\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0028 - accuracy: 0.9993\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0090 - accuracy: 0.9977\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0078 - accuracy: 0.9977\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0076 - accuracy: 0.9979\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0038 - accuracy: 0.9989\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0066 - accuracy: 0.9982\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0029 - accuracy: 0.9991\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0072 - accuracy: 0.9980\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0056 - accuracy: 0.9985\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0064 - accuracy: 0.9983\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0042 - accuracy: 0.9987\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0067 - accuracy: 0.9981\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0071 - accuracy: 0.9983\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0054 - accuracy: 0.9984\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0035 - accuracy: 0.9990\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0073 - accuracy: 0.9978\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0060 - accuracy: 0.9986\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0047 - accuracy: 0.9988\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0080 - accuracy: 0.9978\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0059 - accuracy: 0.9983\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0050 - accuracy: 0.9988\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0063 - accuracy: 0.9984\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0046 - accuracy: 0.9989\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0040 - accuracy: 0.9987\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0025 - accuracy: 0.9992\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0036 - accuracy: 0.9990\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0064 - accuracy: 0.9982\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0055 - accuracy: 0.9987\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0071 - accuracy: 0.9981\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0057 - accuracy: 0.9986\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0037 - accuracy: 0.9991\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0060 - accuracy: 0.9984\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0044 - accuracy: 0.9986\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0064 - accuracy: 0.9981\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0057 - accuracy: 0.9984\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0041 - accuracy: 0.9990\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0043 - accuracy: 0.9988\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0034 - accuracy: 0.9991\n",
      "600/600 [==============================] - 12s 19ms/step - loss: 0.0069 - accuracy: 0.9980\n",
      "600/600 [==============================] - 12s 19ms/step - loss: 0.0071 - accuracy: 0.9983\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0043 - accuracy: 0.9989\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0028 - accuracy: 0.9993\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0033 - accuracy: 0.9989\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0049 - accuracy: 0.9987\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0061 - accuracy: 0.9985\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0027 - accuracy: 0.9992\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0056 - accuracy: 0.9986\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0011 - accuracy: 0.9996\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0013 - accuracy: 0.9995\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 0.0058 - accuracy: 0.9984\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(),\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "import extensionbase\n",
    "gen = extensionbase.gen_extension_base(x_train, y_train)\n",
    "loss = []\n",
    "for _ in range(100):\n",
    "    x, y = next(gen)\n",
    "    h = model.fit(x, y, batch_size=77)\n",
    "    loss.append(h.history[\"loss\"][-1])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 1345.8899 - accuracy: 0.6106\n"
     ]
    },
    {
     "data": {
      "text/plain": "[1345.889892578125, 0.6105999946594238]"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test_cat)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "model.save(\"Model_CNN_ex_128_10\", save_format=\"h5\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
